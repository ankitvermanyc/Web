<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Gemini Voice Assistant</title>
    <style>
        body { 
            display: flex; 
            flex-direction: column; 
            align-items: center; 
            justify-content: center; 
            height: 100vh; 
            margin: 0; 
            background: #222; 
            color: white; 
            font-family: sans-serif;
            text-align: center;
        }
        
        button {
            padding: 25px 50px; 
            font-size: 1.5rem; 
            border-radius: 50px; 
            border: none;
            background: #4e8cff; 
            color: white; 
            margin-bottom: 20px;
            box-shadow: 0 4px 15px rgba(78, 140, 255, 0.4);
            cursor: pointer;
        }

        button:active {
            transform: scale(0.95);
        }

        #log { 
            color: #aaa; 
            font-size: 1rem; 
            padding: 20px; 
            max-width: 80%;
            line-height: 1.5;
        }
    </style>
</head>
<body>

    <button id="btn">TAP TO START</button>
    
    <div id="log">Status: Waiting for you to tap the button...</div>

    <script>
        const btn = document.getElementById('btn');
        const log = document.getElementById('log');
        
        // YOUR API KEY
        const API_KEY = "AIzaSyAehS-QGJqkwKu91wQFLoi2uhT_784gU_0"; 

        // 1. CLICK TO ASK PERMISSION
        btn.addEventListener('click', async () => {
            log.textContent = "Status: Asking for Microphone...";
            
            try {
                // This line triggers the browser popup
                const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
                
                log.textContent = "Status: SUCCESS! Microphone is working.";
                btn.style.background = "#2ecc71"; // Turn Green
                btn.textContent = "Listening...";
                
                // 2. IMMEDIATELY START RECORDING FOR DEMO
                startGemini(stream);

            } catch (err) {
                console.error(err);
                log.textContent = "Status: BLOCKED. " + err.message;
                alert("Error: Permission Denied.\n\nTap the Lock icon ðŸ”’ in your address bar -> Permissions -> Reset Microphone.");
            }
        });

        async function startGemini(stream) {
            log.textContent = "Status: Recording... Say something!";
            
            const mediaRecorder = new MediaRecorder(stream);
            const audioChunks = [];

            mediaRecorder.ondataavailable = event => {
                audioChunks.push(event.data);
            };

            mediaRecorder.onstop = async () => {
                log.textContent = "Status: Sending to Gemini...";
                
                const audioBlob = new Blob(audioChunks, { type: 'audio/webm' });
                const base64Audio = await blobToBase64(audioBlob);
                
                await sendToGemini(base64Audio);
            };

            mediaRecorder.start();

            // Record for 4 seconds then stop automatically (Simple Demo)
            setTimeout(() => {
                mediaRecorder.stop();
                btn.textContent = "Thinking...";
            }, 4000);
        }

        async function sendToGemini(base64Audio) {
            const url = `https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key=${API_KEY}`;
            
            const payload = {
                contents: [{
                    parts: [
                        { text: "You are a helpful assistant. Answer briefly." },
                        { inline_data: { mime_type: "audio/webm", data: base64Audio } }
                    ]
                }]
            };

            try {
                const response = await fetch(url, {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify(payload)
                });

                const data = await response.json();
                const aiText = data.candidates[0].content.parts[0].text;
                
                log.textContent = "Gemini: " + aiText;
                speakText(aiText);
                btn.textContent = "Tap to Speak Again";
                btn.style.background = "#4e8cff"; // Reset Blue

            } catch (error) {
                log.textContent = "Error: " + error.message;
            }
        }

        function blobToBase64(blob) {
            return new Promise((resolve) => {
                const reader = new FileReader();
                reader.onloadend = () => resolve(reader.result.split(',')[1]);
                reader.readAsDataURL(blob);
            });
        }

        function speakText(text) {
            window.speechSynthesis.cancel();
            const utterance = new SpeechSynthesisUtterance(text);
            window.speechSynthesis.speak(utterance);
        }
    </script>
</body>
</html>
                log.textContent = "Status: SUCCESS! Mic is active.";
                btn.style.background = "#2ecc71";
                btn.textContent = "Mic Active";
                
                // Stop stream immediately (just wanted permission)
                stream.getTracks().forEach(track => track.stop());
                
                // Now start the real logic (if you want)
                alert("Microphone Permission Granted!");

            } catch (err) {
                log.textContent = "Status: DENIED. " + err.message;
                alert("Error: " + err.message + "\n\nCheck browser settings -> Site Settings -> Microphone.");
            }
        });
    </script>
</body>
</html>
        #gemini-trigger.needs-permission { animation: pulse-blue 2s infinite; }

        @keyframes pulse-red { 0% { box-shadow: 0 0 0 0 rgba(255, 78, 78, 0.7); } 70% { box-shadow: 0 0 0 10px rgba(255, 78, 78, 0); } 100% { box-shadow: 0 0 0 0 rgba(255, 78, 78, 0); } }
        @keyframes pulse-blue { 0% { box-shadow: 0 0 0 0 rgba(78, 140, 255, 0.7); } 70% { box-shadow: 0 0 0 10px rgba(78, 140, 255, 0); } 100% { box-shadow: 0 0 0 0 rgba(78, 140, 255, 0); } }

        .gemini-popup {
            position: absolute; top: 60px; right: 0; width: 320px; background: white; border-radius: 12px; padding: 20px;
            box-shadow: 0 10px 40px rgba(0,0,0,0.15); border: 1px solid #eee;
            opacity: 0; visibility: hidden; transform: translateY(-10px); transition: all 0.3s cubic-bezier(0.16, 1, 0.3, 1); pointer-events: none;
        }
        .gemini-popup.active { opacity: 1; visibility: visible; transform: translateY(0); pointer-events: all; }
        .gemini-popup::before { content: ''; position: absolute; top: -6px; right: 15px; width: 12px; height: 12px; background: white; transform: rotate(45deg); border-left: 1px solid #eee; border-top: 1px solid #eee; }

        .gemini-status { font-size: 0.75rem; text-transform: uppercase; letter-spacing: 1px; color: #999; margin-bottom: 10px; font-weight: 700; }
        .gemini-response { font-size: 0.95rem; color: #333; line-height: 1.5; max-height: 200px; overflow-y: auto; }
        
        .dots span { animation: blink 1.4s infinite both; font-size: 20px; line-height: 10px; }
        .dots span:nth-child(2) { animation-delay: 0.2s; } .dots span:nth-child(3) { animation-delay: 0.4s; }
        @keyframes blink { 0% { opacity: 0.2; } 20% { opacity: 1; } 100% { opacity: 0.2; } }
    </style>
</head>
<body>

    <header>
        <div class="logo">MyCorp Inc.</div>
        <div class="gemini-widget">
            <button id="gemini-trigger" class="needs-permission" title="Click to Enable Mic">
                <svg viewBox="0 0 24 24"><path d="M12 14c1.66 0 3-1.34 3-3V5c0-1.66-1.34-3-3-3S9 3.34 9 5v6c0 1.66 1.34 3 3 3z"/><path d="M17 11c0 2.76-2.24 5-5 5s-5-2.24-5-5H5c0 3.53 2.61 6.43 6 6.92V21h2v-3.08c3.39-.49 6-3.39 6-6.92h-2z"/></svg>
            </button>
            <div class="gemini-popup" id="gemini-popup">
                <div class="gemini-status" id="gemini-status">Setup Required</div>
                <div class="gemini-response" id="gemini-text">Click the microphone icon to allow voice access.</div>
            </div>
        </div>
    </header>

    <div class="main-content">
        <div class="hero-card">
            <h1>Welcome to the Future</h1>
            <p>This demo asks for microphone permission gracefully.</p>
            <p>1. <strong>First Click:</strong> Asks for permission.<br>2. <strong>Then:</strong> Hold to speak.</p>
        </div>
    </div>

    <script>
        // --- CONFIG ---
        const API_KEY = "AIzaSyAehS-QGJqkwKu91wQFLoi2uhT_784gU_0";
        const MODEL_NAME = "gemini-3-flash-preview";

        // --- ELEMENTS ---
        const triggerBtn = document.getElementById('gemini-trigger');
        const popup = document.getElementById('gemini-popup');
        const statusEl = document.getElementById('gemini-status');
        const textEl = document.getElementById('gemini-text');

        let mediaRecorder;
        let audioChunks = [];
        let globalStream = null; // Store the stream globally
        let isPermissionGranted = false;

        // --- 1. PERMISSION HANDLING ---
        
        async function requestMicrophone() {
            try {
                // Open popup to show we are trying
                popup.classList.add('active');
                statusEl.textContent = "Requesting Access...";
                textEl.textContent = "Please click 'Allow' in your browser pop-up.";

                // The browser prompt happens here
                globalStream = await navigator.mediaDevices.getUserMedia({ audio: true });
                
                // Success
                isPermissionGranted = true;
                triggerBtn.classList.remove('needs-permission'); // Stop pulsing blue
                triggerBtn.title = "Hold to Speak";
                statusEl.textContent = "Ready";
                statusEl.style.color = "#4e8cff";
                textEl.textContent = "Microphone connected! Now, click and HOLD the button to speak.";

            } catch (err) {
                console.error("Permission denied:", err);
                statusEl.textContent = "Error";
                statusEl.style.color = "#ff4e4e";
                textEl.textContent = "Microphone permission was denied. Please reset permissions in your browser settings.";
            }
        }

        // --- 2. RECORDING LOGIC ---

        function startRecording() {
            // Safety check: if no permission, do nothing (wait for click event to handle it)
            if (!isPermissionGranted || !globalStream) return;

            popup.classList.add('active');
            
            let options = { mimeType: 'audio/webm' };
            if (!MediaRecorder.isTypeSupported('audio/webm')) {
                options.mimeType = MediaRecorder.isTypeSupported('audio/mp4') ? 'audio/mp4' : '';
            }

            // Reuse the global stream
            mediaRecorder = new MediaRecorder(globalStream, options);
            audioChunks = [];

            mediaRecorder.ondataavailable = e => { if (e.data.size > 0) audioChunks.push(e.data); };
            mediaRecorder.onstop = processAudio; // Trigger Gemini when stopped

            mediaRecorder.start();
            
            // UI Updates
            triggerBtn.classList.add('recording');
            statusEl.textContent = "Listening...";
            statusEl.style.color = "#ff4e4e";
            textEl.innerHTML = '<div class="dots"><span>.</span><span>.</span><span>.</span></div>';
        }

        function stopRecording() {
            if (mediaRecorder && mediaRecorder.state !== 'inactive') {
                mediaRecorder.stop();
                triggerBtn.classList.remove('recording');
                statusEl.textContent = "Thinking...";
                statusEl.style.color = "#4e8cff";
            }
        }

        // --- 3. GEMINI API ---

        async function processAudio() {
            // Note: In the 'onstop' event, audioChunks is ready
            const audioBlob = new Blob(audioChunks, { type: mediaRecorder.mimeType });
            const base64Audio = await blobToBase64(audioBlob);

            const url = `https://generativelanguage.googleapis.com/v1beta/models/${MODEL_NAME}:generateContent?key=${API_KEY}`;
            
            const payload = {
                contents: [{
                    parts: [
                        { text: "You are a helpful assistant. Be concise." },
                        { inline_data: { mime_type: mediaRecorder.mimeType, data: base64Audio } }
                    ]
                }]
            };

            try {
                const response = await fetch(url, {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify(payload)
                });

                const data = await response.json();
                if (!response.ok) throw new Error(data.error?.message || "API Error");

                const aiText = data.candidates[0].content.parts[0].text;
                
                statusEl.textContent = "Gemini:";
                statusEl.style.color = "#888";
                typeWriterEffect(aiText);
                speakText(aiText);

            } catch (error) {
                statusEl.textContent = "Error";
                textEl.textContent = error.message;
            }
        }
